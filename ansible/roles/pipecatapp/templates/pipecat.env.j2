#!/bin/sh
export LLAMA_API_SERVICE_NAME="{{ llama_api_service_name | default('llamacpp-rpc-api') }}"
export USE_SUMMARIZER="{{ use_summarizer | default('false') }}"
export STT_SERVICE="{{ stt_service | default('faster-whisper') }}"
export PIECAT_API_KEYS="{{ pipecat_api_keys }}"
export EXTERNAL_EXPERTS_CONFIG='{{ external_experts_config | to_json }}'
export OPENAI_API_KEY="{{ openai_api_key }}"
export OPENROUTER_API_KEY="{{ openrouter_api_key }}"
# Use the memory service exposed on the cluster IP (port 8000 mapped in memory_service.nomad.j2)
export MEMORY_SERVICE_URL="http://{{ cluster_ip }}:8000"

export CONSUL_HOST="{{ cluster_ip }}"
export CONSUL_PORT="{{ consul_http_port }}"
export WEB_PORT="{{ nanochat_port | default(8000) }}"
export YOLO_MODEL_PATH="{{ nomad_models_dir }}/vision/yolov8n.pt"
export PRIMA_API_SERVICE_NAME="llama-api-main"
