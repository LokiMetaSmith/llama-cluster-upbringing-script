job "{{ job_name | default('pipecat-app') }}" {
  datacenters = ["dc1"]
  type        = "service"

  group "pipecat-group" {
    count = 1

    update {
      max_parallel     = 3
      min_healthy_time = "30s"
      healthy_deadline = "15m"
      progress_deadline = "20m"
      auto_revert      = true
      canary           = 0
    }

    reschedule {
      attempts  = 3
      interval  = "10m"
      delay     = "30s"
      unlimited = false
    }

    {% set env_vars %}
    env {
      LLAMA_API_SERVICE_NAME = "{{ llama_api_service_name | default('llamacpp-rpc-api') }}"
      USE_SUMMARIZER         = "{{ use_summarizer | default('false') }}"
      STT_SERVICE            = "{{ stt_service | default('faster-whisper') }}"
      PIECAT_API_KEYS        = "{{ pipecat_api_keys }}"
      EXTERNAL_EXPERTS_CONFIG = "{{ external_experts_config | to_json | replace('\"', '\\\"') }}"
      OPENAI_API_KEY         = "{{ openai_api_key }}"
      OPENROUTER_API_KEY     = "{{ openrouter_api_key }}"
      MEMORY_SERVICE_URL     = "http://{{ cluster_ip }}:8000"
      CONSUL_HOST            = "{{ cluster_ip }}"
      CONSUL_PORT            = "{{ consul_http_port }}"
      CONSUL_HTTP_TOKEN      = "{{ consul_bootstrap_token | default('') }}"
      ROUTER_PORT            = "{{ router_port }}"
      LLAMA_API_URL          = "http://{{ cluster_ip }}:{{ router_port }}/v1"
      WEB_PORT               = "${NOMAD_PORT_http}"
      YOLO_MODEL_PATH        = "{{ nomad_models_dir }}/vision/yolov8n.pt"
      PRIMA_API_SERVICE_NAME = "llama-api-main"
    }
    {% endset %}

    {% if pipecat_deployment_style == 'docker' %}
    network {
      mode = "host"
      port "http" {
        static = {{ nanochat_port }}
      }
    }

    {% if sound_enabled | default(false) %}
    volume "snd" {
      type   = "host"
      source = "snd"
    }
    {% endif %}
    {% else %}
    network {
      mode = "host"
      port "http" {
        static = {{ nanochat_port }}
      }
    }
    {% endif %}

    service {
      name     = "{{ service_name | default('pipecat-app') }}"
      port     = "http"
      provider = "consul"
      address  = "{{ cluster_ip }}"
      tags     = ["pipecat", "ai-agent", "version=1.0"]

      check {
        name     = "alive"
        type     = "http"
        path     = "/health"
        interval = "20s"
        timeout  = "5s"
      }

      check {
        name     = "pipeline-status"
        type     = "http"
        path     = "/api/status"
        interval = "30s"
        timeout  = "5s"
      }
    }

    {% if pipecat_deployment_style == 'docker' %}
    task "pipecat-task" {
      driver = "docker"
      {{ env_vars }}

      config {
        image = "pipecatapp:local"
        force_pull = false
        ports = ["http"]
        # Mount volumes for models and config. Models are read-only.
        # Assumes /app is the WORKDIR in the container, where pipecat_config.json will be placed.
        volumes = [
          "/opt/nomad/models:/opt/nomad/models:ro",
          "/opt/pipecatapp/pipecat_config.json:/app/pipecat_config.json:ro",
        ]
        # Pass through the sound device to the container
        {% if sound_enabled | default(false) %}
        devices = [
          {
            host_path      = "/dev/snd"
            container_path = "/dev/snd"
          }
        ]
        {% endif %}
      }

      resources {
        cpu    = 1000 # 1 GHz
        memory = 2048 # 2048 MB
      }
    }
    {% else %}
    task "pipecat-task" {
      driver = "raw_exec"
      {{ env_vars }}

      config {
        command = "/opt/pipecatapp/start_pipecat.sh"
      }

      resources {
        cpu    = 1000 # 1 GHz
        memory = 1024 # 4 GB
      }
    }
    {% endif %}
  }
}
