job "{{ job_name | default('pipecat-app') }}" {
  datacenters = ["dc1"]
  type        = "service"

  group "pipecat-group" {
    count = 1

    {% if pipecat_deployment_style == 'docker' %}
    network {
      mode = "host"
      port "http" {
        to = 8000
      }
    }

    volume "snd" {
      type   = "host"
      source = "snd"
    }
    {% else %}
    network {
      mode = "host"
      port "http" {}
    }
    {% endif %}

    service {
      name     = "{{ service_name | default('pipecat-app') }}"
      port     = "http"
      provider = "consul"

      check {
        type         = "http"
        path         = "/health"
        interval     = "10s"
        timeout      = "2s"
        address_mode = "host"
        {% if pipecat_deployment_style == 'docker' %}
        {% endif %}
      }
    }

    {% if pipecat_deployment_style == 'docker' %}
    task "pipecat-task" {
      driver = "docker"

      config {
        image = "pipecatapp:latest"
        force_pull = false
        ports = ["http"]
        # Mount volumes for models and config. Models are read-only.
        # Assumes /app is the WORKDIR in the container, where pipecat_config.json will be placed.
        volumes = [
          "/opt/nomad/models:/opt/nomad/models:ro",
          "/opt/pipecatapp/pipecat_config.json:/app/pipecat_config.json:ro",
        ]
        # Pass through the sound device to the container
        devices = [
          {
            host_path      = "/dev/snd"
            container_path = "/dev/snd"
          }
        ]
      }

      env {
        # This should match the service name of the main llama-expert job
        LLAMA_API_SERVICE_NAME = "{{ llama_api_service_name }}"
        # Set to "true" to enable the summarizer tool
        USE_SUMMARIZER = "{{ use_summarizer }}"
        # The vision and embedding models are now hardcoded in the application
        # to load from the unified /opt/nomad/models directory.
        STT_SERVICE = "{{ stt_service }}"
      }

      resources {
        cpu    = 1000 # 1 GHz
        memory = 1024 # 4 GB
      }
    }
    {% else %}
    task "pipecat-task" {
      driver = "raw_exec"

      env {
        WEB_PORT = "${NOMAD_PORT_http}"
      }
 
      config {
        command = "/opt/pipecatapp/start_pipecat.sh"
      }

      resources {
        cpu    = 1000 # 1 GHz
        memory = 1024 # 4 GB
      }
    }
    {% endif %}
  }
}
