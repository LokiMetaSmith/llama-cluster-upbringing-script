- name: Download Nomad
  ansible.builtin.get_url:
    url: "{{ nomad_zip_url }}"
    dest: "/tmp/nomad.zip"
    mode: '0644'
    timeout: 30
  register: download_task
  until: download_task is success
  retries: 5
  delay: 10
  check_mode: no

- name: Unzip Nomad
  ansible.builtin.unarchive:
    src: "/tmp/nomad.zip"
    dest: "/tmp"
    remote_src: yes
    creates: /tmp/nomad
  check_mode: no

- name: Get version of the existing Nomad binary
  ansible.builtin.command:
    cmd: /usr/local/bin/nomad --version
  register: existing_nomad_version
  changed_when: false
  ignore_errors: true

- name: Get version of the new Nomad binary
  ansible.builtin.command:
    cmd: /tmp/nomad --version
  register: new_nomad_version
  changed_when: false

- name: Reset Nomad state if version has changed
  when: >
    (existing_nomad_version.stdout is defined and
    new_nomad_version.stdout is defined and
    existing_nomad_version.stdout != new_nomad_version.stdout) and
    (cleanup_services | bool)
  block:
    - name: Stop Nomad service
      ansible.builtin.systemd:
        name: nomad
        state: stopped
      become: yes
      ignore_errors: yes

    - name: Clear old Nomad server state
      ansible.builtin.file:
        path: "{{ nomad_data_dir }}/server"
        state: absent
      become: yes

    - name: Clear old Nomad client state
      ansible.builtin.file:
        path: "{{ nomad_data_dir }}/client"
        state: absent
      become: yes

- name: Move Nomad to /usr/local/bin
  ansible.builtin.copy:
    src: /tmp/nomad
    dest: /usr/local/bin/nomad
    remote_src: yes
    mode: '0755'
  become: yes

- name: Check for nomad binary to ensure idempotency
  ansible.builtin.stat:
    path: /usr/local/bin/nomad
  register: nomad_binary_stat

- name: Ensure old, conflicting Nomad config files are removed
  ansible.builtin.file:
    path: "{{ item }}"
    state: absent
  loop:
    - /etc/nomad.d/client.hcl
    - /etc/nomad.d/server.hcl
    - /etc/nomad.d/nomad.hcl
  when: not nomad_binary_stat.stat.exists
  become: yes

- name: Create Nomad config directory
  ansible.builtin.file:
    path: /etc/nomad.d
    state: directory
    owner: root
    group: root
    mode: '0755'
  become: yes

- name: Create Nomad models directory
  ansible.builtin.file:
    path: "{{ nomad_models_dir }}"
    state: directory
    owner: root
    group: root
    mode: '0755'
  become: yes

- name: Create Nomad jobs directory
  ansible.builtin.file:
    path: "{{ nomad_jobs_dir }}"
    state: directory
    owner: root
    group: root
    mode: '0755'
  become: yes

- name: Copy Nomad systemd service file
  ansible.builtin.template:
    src: nomad.service.j2
    dest: /etc/systemd/system/nomad.service
    mode: '0644'
  become: yes
  notify:
    - Reload systemd
    - Restart nomad

- name: Force immediate handler flush to ensure systemd is reloaded
  meta: flush_handlers

- name: Fetch Consul management token
  ansible.builtin.slurp:
    src: /etc/consul.d/management_token
  register: consul_token_file
  delegate_to: "{{ (groups['controller_nodes'] | first) if ('controller_nodes' in groups and groups['controller_nodes']) else inventory_hostname }}"
  run_once: true
  become: yes
  ignore_errors: yes
  tags:
    - nomad

- name: Set Consul token fact
  set_fact:
    consul_bootstrap_token: "{{ consul_token_file['content'] | b64decode | trim }}"
  when: consul_token_file is success and consul_token_file.content is defined
  run_once: true
  tags:
    - nomad

- name: Deploy Nomad server configuration for controller nodes
  ansible.builtin.template:
    src: server.hcl.j2
    dest: /etc/nomad.d/server.hcl
    owner: root
    group: root
    mode: "0644"
  vars:
    is_controller: true
  become: yes
  when: "'controller_nodes' in groups and inventory_hostname in groups['controller_nodes']"
  notify:
    - Restart nomad


- name: Copy Nomad config for local bootstrap
  ansible.builtin.template:
    src: nomad.hcl.server.j2
    dest: "{{ nomad_config_dir }}/nomad.hcl"
  when: "inventory_hostname == 'localhost' and 'controller' not in group_names and 'workers' not in group_names"
  notify:
    - Restart nomad

- name: Deploy Nomad client configuration for worker nodes
  ansible.builtin.template:
    src: client.hcl.j2
    dest: /etc/nomad.d/client.hcl
    owner: root
    group: root
    mode: "0644"
  become: yes
  when: "'workers' in groups and inventory_hostname in groups['workers']"
  notify:
    - Restart nomad

- name: Create systemd override directory for Nomad service
  ansible.builtin.file:
    path: /etc/systemd/system/nomad.service.d
    state: directory
  become: yes

- name: Add override to enforce startup order
  ansible.builtin.copy:
    dest: /etc/systemd/system/nomad.service.d/override.conf
    content: |
      [Unit]
      Wants=consul.service docker.service
      After=consul.service docker.service
  become: yes

- name: Set NOMAD_ADDR environment variable for all users
  ansible.builtin.template:
    dest: /etc/profile.d/nomad.sh
    mode: '0755'
    src: nomad.sh.j2
  become: yes

- name: Ensure CNI plugin directory exists
  ansible.builtin.file:
    path: /opt/cni/bin
    state: directory
    mode: '0755'
  become: yes
  check_mode: no

- name: Download CNI plugins tarball
  ansible.builtin.get_url:
    url: "{{ cni_url }}"
    dest: /tmp/cni-plugins.tgz
    mode: '0644'
    timeout: 30
  check_mode: no

- name: Extract CNI plugins into /opt/cni/bin
  ansible.builtin.unarchive:
    src: /tmp/cni-plugins.tgz
    dest: /opt/cni/bin
    remote_src: yes
  become: yes
  check_mode: no

- name: Ensure /dev/snd directory exists for Nomad volume
  ansible.builtin.file:
    path: /dev/snd
    state: directory
    mode: '0755'
  become: yes

- name: Ensure /opt/pipecatapp directory exists for Nomad volume
  ansible.builtin.file:
    path: /opt/pipecatapp
    state: directory
    owner: "{{ target_user | default('pipecatapp') }}"
    group: "{{ target_user | default('pipecatapp') }}"
    mode: '0755'
  become: yes

- name: Create Nomad volumes directory before service setup
  ansible.builtin.file:
    path: "{{ nomad_volumes_dir }}"
    state: directory
    owner: "{{ target_user | default('pipecatapp') }}"
    group: "{{ target_user | default('pipecatapp') }}"
    mode: '0755'
  become: yes

- name: Create subdirectories for Nomad volumes
  ansible.builtin.file:
    path: "{{ nomad_volumes_dir }}/{{ item }}"
    state: directory
    owner: "{{ target_user | default('pipecatapp') }}"
    group: "{{ target_user | default('pipecatapp') }}"
    mode: '0755'
  loop:
    - mqtt-data
    - ha-config
    - world_model_storage
  become: yes

- name: Start and enable Nomad service
  ansible.builtin.systemd:
    name: nomad
    state: started
    enabled: yes
  become: yes
  async: 45
  poll: 5
  register: nomad_service_start
  when: not ansible_check_mode

- name: Wait for Nomad API to be ready
  ansible.builtin.uri:
    url: "http://{{ cluster_ip }}:4646/v1/agent/self"
    status_code: 200
  register: nomad_api_status
  until: nomad_api_status.status == 200
  retries: 12
  delay: 5
  ignore_errors: yes
  when: not ansible_check_mode

- name: Check Nomad service status if start task failed
  when: not ansible_check_mode and (nomad_service_start.failed or nomad_api_status.failed)
  block:
    - name: Get Nomad service status
      ansible.builtin.command: systemctl status nomad --no-pager
      register: nomad_status
      failed_when: false
      changed_when: false
      become: yes

    - name: Display Nomad service status
      ansible.builtin.debug:
        var: nomad_status.stdout_lines

    - name: Get last 50 lines of Nomad logs
      ansible.builtin.command: journalctl -u nomad --no-pager -n 50
      register: nomad_logs
      failed_when: false
      changed_when: false
      become: yes

    - name: Display Nomad logs
      ansible.builtin.debug:
        var: nomad_logs.stdout_lines

    - name: Display Nomad logs and fail
      ansible.builtin.fail:
        msg: |
          Nomad service failed to start. Please check the logs above for errors.
          Common issues are misconfigured client.hcl, networking problems,
          or failed dependencies like Consul or Docker.
          Logs:
          {{ nomad_logs.stdout }}
  notify:
    - Restart nomad

- name: Ensure handlers are flushed
  meta: flush_handlers
