- name: Deploy Distributed AI Experts
  hosts: controller_nodes[0] # Run these commands from a single controller node
  connection: local
  gather_facts: no
  become: no

  vars_files:
    - "{{ playbook_dir }}/../../group_vars/all.yaml"
    - "{{ playbook_dir }}/../../group_vars/models.yaml"
    - "{{ playbook_dir }}/../../group_vars/external_experts.yaml"


  vars:
    expected_worker_count: "{{ ((groups['workers'] | default([]) | length) if (groups['workers'] | default([]) | length) > 0 else 1) | int }}"
    # This creates a new list containing only the first model object from each expert's list.
    # The template needs the full object (name, filename, memory_mb, etc.), not just the name.
    expert_primary_models: "{{ expert_models.values() | map('first') | list }}"

  tasks:
    - name: Deploy and run the GPU Provider Pool job for each expert
      include_tasks:
        file: "{{ playbook_dir }}/../../ansible/tasks/deploy_expert_gpu_provider.yaml"
      loop: "{{ expert_models.keys() | list }}"
      loop_control:
        loop_var: item


    - name: Deploy the Expert Orchestrator services
      ansible.builtin.command: >
        nomad job run
        -var="job_name=expert-{{ item }}"
        -var="service_name=expert-api-{{ item }}"
        -var="rpc_pool_job_name=llamacpp-rpc-pool"
                {{ playbook_dir }}/../../ansible/jobs/expert.nomad.j2
      loop: "{{ experts }}"
      changed_when: true
