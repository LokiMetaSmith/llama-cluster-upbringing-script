# -----------------------------------------------------------------------------
# Ansible Playbook: Debug Llama.cpp RPC Template
#
# Purpose:
# This playbook provides a fast way to render the main `llamacpp-rpc.nomad`
# job file from its Jinja2 template. It's designed for quick debugging and
# validation of the template without running the entire main bootstrap script.
#
# How it Works:
# 1. It loads the necessary model definitions from `group_vars/models.yaml`.
# 2. It defines the variables (`job_name`, `model_list`, etc.) that the
#    Nomad template expects.
# 3. It uses the `ansible.builtin.template` module to process
#    `ansible/jobs/llamacpp-rpc.nomad` and saves the output to a new file named
#    `rendered_llamacpp_rpc_job.nomad` in the project's root directory.
#
# -----------------------------------------------------------------------------
- name: Debug and Render Llama.cpp RPC Nomad Template
  hosts: localhost
  connection: local
  gather_facts: no

  vars_files:
    - group_vars/models.yaml

  # Define the variables that the prima-expert.nomad template expects.
  # This simulates how the main `llama_cpp` role would deploy the default expert.
  vars:
    job_name: "llamacpp-rpc"
    service_name: "llamacpp-rpc-api"
    namespace: "default"
    model_list: "{{ expert_models['main'] }}"
    worker_count: 1

  tasks:
    - name: Render the Prima Expert Nomad job from template
      ansible.builtin.template:
        # Source: The Jinja2 template file for the Nomad job.
        src: ansible/jobs/prima-expert.nomad
        # Destination: The output file. This will be a pure, valid HCL file
        # that you can test directly with the `nomad` command.
        dest: ./rendered_prima_expert_job.nomad
        # Set standard file permissions for the rendered file.
        mode: '0644'
