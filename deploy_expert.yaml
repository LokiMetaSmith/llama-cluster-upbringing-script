- name: Deploy Expert Job
  hosts: localhost
  connection: local
  gather_facts: yes

  vars_files:
    - group_vars/models.yaml

  vars:
    job_name: "expert-main"
    service_name: "llama-api-main"
    nomad_namespace: "default"
    worker_count: 1
    rpc_pool_job_name: "llamacpp-rpc-pool"
    current_expert: "main"
    expert_benchmark_data: {'main': {'avg_tokens': 0.0}}
    avg_tokens_for_template: "{{ expert_benchmark_data[current_expert].avg_tokens | float | round(2) }}"
    model_list: "{{ expert_models[current_expert] }}"
    current_expert_tags:
      - "expert={{ current_expert }}"
      - "avg_tps={{ avg_tokens_for_template }}"
      - "memory_mb={{ ansible_memtotal_mb }}"
      - "models={{ model_list | map(attribute='filename') | join(',') }}"

  tasks:
    - name: Create virtual environment
      ansible.builtin.command: python3 -m venv /tmp/jinja2_venv
      args:
        creates: /tmp/jinja2_venv/bin/pip
      check_mode: no

    - name: Install jinja2 into the virtual environment
      ansible.builtin.pip:
        executable: /tmp/jinja2_venv/bin/pip
        name: jinja2
        state: present

    - name: Create tmp directory in project root
      ansible.builtin.file:
        path: "{{ playbook_dir }}/tmp"
        state: directory
        mode: '0755'

    - name: Create temporary JSON file with variables
      ansible.builtin.copy:
        content: "{{ {
            'expert_models': expert_models,
            'current_expert': current_expert,
            'avg_tokens': avg_tokens_for_template,
            'current_expert_tags': current_expert_tags,
            'job_name': job_name,
            'service_name': service_name,
            'rpc_pool_job_name': rpc_pool_job_name,
            'ansible_memtotal_mb': ansible_memtotal_mb
          } | to_json }}"
        dest: "{{ playbook_dir }}/tmp/expert-{{ current_expert }}-vars.json"
        mode: '0644'

    - name: Render the Llama Expert job template with custom variables
      ansible.builtin.shell:
        cmd: |
          /tmp/jinja2_venv/bin/python {{ playbook_dir }}/render_template.py \
          {{ playbook_dir }}/ansible/jobs/expert.nomad.j2 \
          {{ playbook_dir }}/tmp/expert-{{ current_expert }}-vars.json \
          > {{ playbook_dir }}/tmp/expert-{{ current_expert }}.nomad

    - name: Run nomad version
      ansible.builtin.command: nomad version
      register: nomad_version_output
      changed_when: false

    - name: Display Nomad version
      ansible.builtin.debug:
        var: nomad_version_output.stdout_lines

    - name: "Wait for Nomad API to be ready"
      ansible.builtin.uri:
        url: http://127.0.0.1:4646/v1/status/leader
        method: GET
        status_code: 200
      register: nomad_api_status
      until: "nomad_api_status.status == 200"
      retries: 12
      delay: 5

    - name: "Run the custom Llama Expert job in Nomad"
      ansible.builtin.shell:
        cmd: "nomad job run {{ playbook_dir }}/tmp/expert-{{ current_expert }}.nomad"
        executable: /bin/bash

    - name: "Display Nomad run output"
      ansible.builtin.debug:
        var: nomad_run_result.stdout_lines
